{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBaiCnJkKtPG+IFjJeJRPV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/twyeh/highenergy/blob/main/flavio_fits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_jTAKQuksqf"
      },
      "outputs": [],
      "source": [
        "\"\"\"A fit is a collection of observables and parameters that can be used to\n",
        "perform statistical analyses within a particular statistical framework.\n",
        "\n",
        "Fits are instances of descendants of the `Fit` class (which is not meant\n",
        "to be used directly)\n",
        "\n",
        "Note that this module has been deprecated as of flavio v1.6.0. Please\n",
        "use the `flavio.statistics.likelihood` module instead.\"\"\"\n",
        "\n",
        "import warnings\n",
        "warnings.warn(\"The `flavio.statistics.fits` module has been deprecated\"\n",
        "              \" as of flavio v1.6.0. Please use the `flavio.statistics.likelihood`\"\n",
        "              \" module instead.\",\n",
        "              DeprecationWarning, stacklevel=2)\n",
        "\n",
        "\n",
        "import flavio\n",
        "import numpy as np\n",
        "from flavio.statistics.probability import NormalDistribution, MultivariateNormalDistribution\n",
        "from flavio.math.optimize import minimize_robust\n",
        "from collections import Counter, OrderedDict\n",
        "import warnings\n",
        "import inspect\n",
        "from multiprocessing import Pool\n",
        "import scipy.optimize\n",
        "import pickle\n",
        "from functools import partial\n",
        "import yaml\n",
        "\n",
        "\n",
        "class Fit(flavio.NamedInstanceClass):\n",
        "    \"\"\"Base class for fits. Not meant to be used directly.\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 name,\n",
        "                 par_obj=flavio.default_parameters,\n",
        "                 fit_parameters=None,\n",
        "                 nuisance_parameters=None,\n",
        "                 observables=None,\n",
        "                 fit_wc_names=None,\n",
        "                 fit_wc_function=None,\n",
        "                 fit_wc_priors=None,\n",
        "                 input_scale=160.,\n",
        "                 exclude_measurements=None,\n",
        "                 include_measurements=None,\n",
        "                 fit_wc_eft='WET',\n",
        "                 fit_wc_basis='flavio',\n",
        "                ):\n",
        "        if fit_parameters is None:\n",
        "            self.fit_parameters = []\n",
        "        else:\n",
        "            self.fit_parameters = fit_parameters\n",
        "        if nuisance_parameters is None:\n",
        "            self.nuisance_parameters = []\n",
        "        elif nuisance_parameters == 'all':\n",
        "            self.nuisance_parameters = par_obj.all_parameters\n",
        "        else:\n",
        "            self.nuisance_parameters = nuisance_parameters\n",
        "        if observables is None:\n",
        "            raise ValueError(\"'observables' is empty: you must specify at least one fit observable\")\n",
        "        if fit_wc_names is not None:\n",
        "            warnings.warn(\"The 'fit_wc_names' argument is no longer necessary \"\n",
        "            \"as of flavio v0.19 and might be removed in the future.\",\n",
        "            FutureWarning)\n",
        "        # some checks to make sure the input is sane\n",
        "        for p in self.nuisance_parameters:\n",
        "            # check that nuisance parameters are constrained\n",
        "            assert p in par_obj._parameters.keys(), \"Parameter \" + p + \" not found in Constraints\"\n",
        "        for obs in observables:\n",
        "            # check that observables exist\n",
        "            try:\n",
        "                if isinstance(obs, tuple):\n",
        "                    flavio.classes.Observable[obs[0]]\n",
        "                elif isinstance(obs, dict):\n",
        "                    flavio.classes.Observable[obs['name']]\n",
        "                elif isinstance(obs, str):\n",
        "                    flavio.classes.Observable[obs]\n",
        "                else:\n",
        "                    ValueError(\"Unexpected form of observable: {}\".format(obs))\n",
        "            except:\n",
        "                raise ValueError(\"Observable \" + str(obs) + \" not found!\")\n",
        "        _obs_measured = set()\n",
        "        if exclude_measurements and include_measurements:\n",
        "            raise ValueError(\"The options exclude_measurements and include_measurements must not be specified simultaneously\")\n",
        "        # check that no parameter appears as fit *and* nuisance parameter\n",
        "        intersect = set(self.fit_parameters).intersection(self.nuisance_parameters)\n",
        "        assert intersect == set(), \"Parameters appearing as fit_parameters and nuisance_parameters: \" + str(intersect)\n",
        "        # check that the Wilson coefficient function works\n",
        "        if fit_wc_function is not None: # if list of WC names not empty\n",
        "            try:\n",
        "                self.fit_wc_names = tuple(inspect.signature(fit_wc_function).parameters.keys())\n",
        "                fit_wc_function(**{fit_wc_name: 1e-6 for fit_wc_name in self.fit_wc_names})\n",
        "            except:\n",
        "                raise ValueError(\"Error in calling the Wilson coefficient function\")\n",
        "        else:\n",
        "            self.fit_wc_names = tuple()\n",
        "        # now that everything seems fine, we can call the init of the parent class\n",
        "        super().__init__(name)\n",
        "        self.par_obj = par_obj\n",
        "        self.parameters_central = self.par_obj.get_central_all()\n",
        "        self.exclude_measurements = exclude_measurements\n",
        "        self.include_measurements = include_measurements\n",
        "        self.fit_wc_function = fit_wc_function\n",
        "        self.fit_wc_priors = fit_wc_priors\n",
        "        self.observables = observables\n",
        "        self.input_scale = input_scale\n",
        "        self._warn_meas_corr\n",
        "\n",
        "        # check that observables are constrained\n",
        "        for m_name in self.get_measurements:\n",
        "            m_obj = flavio.Measurement[m_name]\n",
        "            _obs_measured.update(m_obj.all_parameters)\n",
        "        missing_obs = set(observables) - set(_obs_measured).intersection(set(observables))\n",
        "        assert missing_obs == set(), \"No measurement found for the observables: \" + str(missing_obs)\n",
        "\n",
        "        self.dimension = len(self.fit_parameters) + len(self.nuisance_parameters) + len(self.fit_wc_names)\n",
        "        self.eft = fit_wc_eft\n",
        "        self.basis = fit_wc_basis\n",
        "\n",
        "    @property\n",
        "    def get_central_fit_parameters(self):\n",
        "        \"\"\"Return a numpy array with the central values of all fit parameters.\"\"\"\n",
        "        return np.asarray([self.parameters_central[p] for p in self.fit_parameters])\n",
        "\n",
        "    @property\n",
        "    def get_random_fit_parameters(self):\n",
        "        \"\"\"Return a numpy array with random values for all fit parameters.\"\"\"\n",
        "        all_random = self.par_obj.get_random_all()\n",
        "        return np.asarray([all_random[p] for p in self.fit_parameters])\n",
        "\n",
        "    @property\n",
        "    def get_random_wilson_coeffs(self):\n",
        "        \"\"\"Return a numpy array with random values for all Wilson coefficients.\"\"\"\n",
        "        if self.fit_wc_priors is None:\n",
        "            return None\n",
        "        all_random = self.fit_wc_priors.get_random_all()\n",
        "        return np.asarray([all_random[p] for p in self.fit_wc_names])\n",
        "\n",
        "    @property\n",
        "    def get_central_nuisance_parameters(self):\n",
        "        \"\"\"Return a numpy array with the central values of all nuisance parameters.\"\"\"\n",
        "        return np.asarray([self.parameters_central[p] for p in self.nuisance_parameters])\n",
        "\n",
        "    @property\n",
        "    def get_random_nuisance_parameters(self):\n",
        "        \"\"\"Return a numpy array with random values for all nuisance parameters.\"\"\"\n",
        "        all_random = self.par_obj.get_random_all()\n",
        "        return np.asarray([all_random[p] for p in self.nuisance_parameters])\n",
        "\n",
        "    @property\n",
        "    def get_measurements(self):\n",
        "        \"\"\"Return a list of all the measurements currently defined that\n",
        "        constrain any of the fit observables.\"\"\"\n",
        "        all_measurements = []\n",
        "        for m_name, m_obj in flavio.classes.Measurement.instances.items():\n",
        "            if m_name.split(' ')[0] == 'Pseudo-measurement':\n",
        "                # skip pseudo measurements generated by FastFit instances\n",
        "                continue\n",
        "            if set(m_obj.all_parameters).isdisjoint(self.observables):\n",
        "                # if set of all observables constrained by measurement is disjoint\n",
        "                # with fit observables, do nothing\n",
        "                continue\n",
        "            else:\n",
        "                # else, add measurement name to output list\n",
        "                all_measurements.append(m_name)\n",
        "        if self.exclude_measurements is None and self.include_measurements is None:\n",
        "            return all_measurements\n",
        "        elif self.exclude_measurements is not None:\n",
        "            return list(set(all_measurements) - set(self.exclude_measurements))\n",
        "        elif self.include_measurements is not None:\n",
        "            return list(set(all_measurements) & set(self.include_measurements))\n",
        "\n",
        "    @property\n",
        "    def _warn_meas_corr(self):\n",
        "        \"\"\"Warn the user if the fit contains multiple correlated measurements of\n",
        "        an observable that is not included in the fit parameters, as this will\n",
        "        lead to inconsistent results.\"\"\"\n",
        "        corr_with = {}\n",
        "        # iterate over all measurements constraining at least one fit obs.\n",
        "        for name in self.get_measurements:\n",
        "            m = flavio.classes.Measurement[name]\n",
        "            # iterate over all fit obs. constrained by this measurement\n",
        "            for obs in set(self.observables) & set(m.all_parameters):\n",
        "                # the constraint on this fit obs.\n",
        "                constraint = m._parameters[obs][1]\n",
        "                # find all the other obs. constrained by this constraint\n",
        "                for c, p in m._constraints:\n",
        "                    if c == constraint:\n",
        "                        par = p\n",
        "                        break\n",
        "                for p in par:\n",
        "                    # if the other obs. are not fit obs., append them to the list\n",
        "                    if p not in self.observables:\n",
        "                        if p not in corr_with:\n",
        "                            corr_with[p] = [obs]\n",
        "                        else:\n",
        "                            corr_with[p].append(obs)\n",
        "        # replace list by a Counter\n",
        "        corr_with = {k: Counter(v) for k, v in corr_with.items() if v}\n",
        "        # warn for all counts > 1\n",
        "        for obs1, counter in corr_with.items():\n",
        "            for obs2, count in counter.items():\n",
        "                if count > 1:\n",
        "                    warnings.warn((\"{} of the measurements in the fit '{}' \"\n",
        "                                   \"constrain both '{}' and '{}', but only the \"\n",
        "                                   \"latter is included among the fit \"\n",
        "                                   \"observables. This can lead to inconsistent \"\n",
        "                                   \"results as the former is profiled over.\"\n",
        "                                   ).format(count, self.name, obs1, obs2))\n",
        "        return corr_with\n",
        "\n",
        "\n",
        "    def array_to_dict(self, x):\n",
        "        \"\"\"Convert a 1D numpy array of floats to a dictionary of fit parameters,\n",
        "        nuisance parameters, and Wilson coefficients.\"\"\"\n",
        "        d = {}\n",
        "        n_fit_p = len(self.fit_parameters)\n",
        "        n_nui_p = len(self.nuisance_parameters)\n",
        "        n_wc = len(self.fit_wc_names)\n",
        "        d['fit_parameters'] = { p: x[i] for i, p in enumerate(self.fit_parameters) }\n",
        "        d['nuisance_parameters'] = { p: x[i + n_fit_p] for i, p in enumerate(self.nuisance_parameters) }\n",
        "        d['fit_wc'] = { p: x[i + n_fit_p + n_nui_p] for i, p in enumerate(self.fit_wc_names) }\n",
        "        return d\n",
        "\n",
        "    def dict_to_array(self, d):\n",
        "        \"\"\"Convert a dictionary of fit parameters,\n",
        "        nuisance parameters, and Wilson coefficients to a 1D numpy array of\n",
        "        floats.\"\"\"\n",
        "        n_fit_p = len(self.fit_parameters)\n",
        "        n_nui_p = len(self.nuisance_parameters)\n",
        "        n_wc = len(self.fit_wc_names)\n",
        "        arr = np.zeros(n_fit_p + n_nui_p + n_wc)\n",
        "        arr[:n_fit_p] = [d['fit_parameters'][p] for p in self.fit_parameters]\n",
        "        arr[n_fit_p:n_fit_p+n_nui_p] = [d['nuisance_parameters'][p] for p in self.nuisance_parameters]\n",
        "        arr[n_fit_p+n_nui_p:]   = [d['fit_wc'][c] for c in self.fit_wc_names]\n",
        "        return arr\n",
        "\n",
        "    @property\n",
        "    def get_random(self):\n",
        "        \"\"\"Get an array with random values for all the fit and nuisance\n",
        "        parameters and Wilson coefficients.\"\"\"\n",
        "        return self._get_random()\n",
        "\n",
        "    def _get_random(self, par=True, nuisance=True, wc=True):\n",
        "        \"\"\"Get an array with random values for all the fit and nuisance\n",
        "        parameters and Wilson coefficients.\n",
        "\n",
        "        If par is False, fit parameters are set to their central values.\n",
        "        If nuisance is False, nuisance parameters are set to their central values.\n",
        "        \"\"\"\n",
        "        arr = np.zeros(self.dimension)\n",
        "        n_fit_p = len(self.fit_parameters)\n",
        "        n_nui_p = len(self.nuisance_parameters)\n",
        "        if par:\n",
        "            arr[:n_fit_p] = self.get_random_fit_parameters\n",
        "        else:\n",
        "            arr[:n_fit_p] = self.get_central_fit_parameters\n",
        "        if nuisance:\n",
        "            arr[n_fit_p:n_fit_p+n_nui_p] = self.get_random_nuisance_parameters\n",
        "        else:\n",
        "            arr[n_fit_p:n_fit_p+n_nui_p] = self.get_central_nuisance_parameters\n",
        "        if wc:\n",
        "            arr[n_fit_p+n_nui_p:] = self.get_random_wilson_coeffs\n",
        "        return arr\n",
        "\n",
        "    @property\n",
        "    def get_random_wilson_coeffs_start(self):\n",
        "        \"\"\"Return a numpy array with random values for all Wilson coefficients\n",
        "        sampling the start_wc_priors distribution.\"\"\"\n",
        "        if self.fit_wc_function is None:\n",
        "            # no Wilson coefficients present\n",
        "            return None\n",
        "        elif self.start_wc_priors is None:\n",
        "            if self.fit_wc_priors is None:\n",
        "                raise ValueError(\"Starting values can only be generated if\"\n",
        "                        \" either fit_wc_priors or start_wc_priors is defined\")\n",
        "            else:\n",
        "                return self.get_random_wilson_coeffs\n",
        "        all_random = self.start_wc_priors.get_random_all()\n",
        "        return np.asarray([all_random[p] for p in self.fit_wc_names])\n",
        "\n",
        "    @property\n",
        "    def get_random_start(self):\n",
        "        \"\"\"Get an array with random values for all the fit and nuisance\n",
        "        parameters with Wilson coefficients set to their SM values\"\"\"\n",
        "        arr = np.zeros(self.dimension)\n",
        "        n_fit_p = len(self.fit_parameters)\n",
        "        n_nui_p = len(self.nuisance_parameters)\n",
        "        arr[:n_fit_p] = self.get_random_fit_parameters\n",
        "        arr[n_fit_p:n_fit_p+n_nui_p] = self.get_random_nuisance_parameters\n",
        "        arr[n_fit_p+n_nui_p:] = self.get_random_wilson_coeffs_start\n",
        "        return arr\n",
        "\n",
        "    def get_par_dict(self, x, par=True, nuisance=True):\n",
        "        \"\"\"Get a dictionary of fit and nuisance parameters from an input array\n",
        "\n",
        "        If par is False, fit parameters are set to their central values.\n",
        "        If nuisance is False, nuisance parameters are set to their central values.\n",
        "        \"\"\"\n",
        "        d = self.array_to_dict(x)\n",
        "        par_dict = self.parameters_central.copy()\n",
        "        if par:\n",
        "            par_dict.update(d['fit_parameters'])\n",
        "        if nuisance:\n",
        "            par_dict.update(d['nuisance_parameters'])\n",
        "        return par_dict\n",
        "\n",
        "    def get_wc_obj(self, x):\n",
        "        wc_obj = flavio.WilsonCoefficients()\n",
        "        # if there are no WCs to be fitted, return the SM WCs\n",
        "        if not self.fit_wc_names:\n",
        "            return wc_obj\n",
        "        d = self.array_to_dict(x)\n",
        "        wc_obj.set_initial(self.fit_wc_function(**d['fit_wc']), self.input_scale,\n",
        "                           eft=self.eft, basis=self.basis)\n",
        "        return wc_obj\n",
        "\n",
        "    def log_prior_parameters(self, x):\n",
        "        \"\"\"Return the prior probability for all fit and nuisance parameters\n",
        "        given an input array\"\"\"\n",
        "        par_dict = self.get_par_dict(x)\n",
        "        exclude_parameters = list(set(par_dict.keys())-set(self.fit_parameters)-set(self.nuisance_parameters))\n",
        "        prob_dict = self.par_obj.get_logprobability_all(par_dict, exclude_parameters=exclude_parameters)\n",
        "        return sum([p for obj, p in prob_dict.items()])\n",
        "\n",
        "    def log_prior_wilson_coeffs(self, x):\n",
        "        \"\"\"Return the prior probability for all Wilson coefficients\n",
        "        given an input array\"\"\"\n",
        "        if self.fit_wc_priors is None:\n",
        "            return 0\n",
        "        wc_dict = self.array_to_dict(x)['fit_wc']\n",
        "        prob_dict = self.fit_wc_priors.get_logprobability_all(wc_dict)\n",
        "        return sum([p for obj, p in prob_dict.items()])\n",
        "\n",
        "    def get_predictions(self, x, par=True, nuisance=True, wc=True):\n",
        "        \"\"\"Get a dictionary with predictions for all observables given an input\n",
        "        array.\n",
        "\n",
        "        If par is False, fit parameters are set to their central values.\n",
        "        If nuisance is False, nuisance parameters are set to their central values.\n",
        "        If wc is False, Wilson coefficients are set to their SM values.\n",
        "        \"\"\"\n",
        "        par_dict = self.get_par_dict(x, par=par, nuisance=nuisance)\n",
        "        if wc:\n",
        "            wc_obj = self.get_wc_obj(x)\n",
        "        else:\n",
        "            wc_obj = flavio.physics.eft._wc_sm\n",
        "        all_predictions = {}\n",
        "        for observable in self.observables:\n",
        "            if isinstance(observable, tuple):\n",
        "                obs_name = observable[0]\n",
        "                _inst = flavio.classes.Observable[obs_name]\n",
        "                all_predictions[observable] = _inst.prediction_par(par_dict, wc_obj, *observable[1:])\n",
        "            else:\n",
        "                _inst = flavio.classes.Observable[observable]\n",
        "                all_predictions[observable] = _inst.prediction_par(par_dict, wc_obj)\n",
        "        return all_predictions\n",
        "\n",
        "    def get_predictions_array(self, x, **kwargs):\n",
        "        pred = self.get_predictions(x, **kwargs)\n",
        "        return np.array([pred[obs] for obs in self.observables])\n",
        "\n",
        "    def log_prior_parameters(self, x):\n",
        "        \"\"\"Return the prior probability (or frequentist likelihood) for all\n",
        "        fit and (!) nuisance parameters given an input array\"\"\"\n",
        "        par_dict = self.get_par_dict(x)\n",
        "        exclude_parameters = list(set(par_dict.keys())-set(self.fit_parameters)-set(self.nuisance_parameters))\n",
        "        prob_dict = self.par_obj.get_logprobability_all(par_dict, exclude_parameters=exclude_parameters)\n",
        "        return sum([p for obj, p in prob_dict.items()])\n",
        "\n",
        "    def log_prior_nuisance_parameters(self, x):\n",
        "        \"\"\"Return the prior probability (or frequentist likelihood) for all\n",
        "        nuisance parameters given an input array\"\"\"\n",
        "        par_dict = self.get_par_dict(x)\n",
        "        exclude_parameters = list(set(par_dict.keys())-set(self.nuisance_parameters))\n",
        "        prob_dict = self.par_obj.get_logprobability_all(par_dict, exclude_parameters=exclude_parameters)\n",
        "        return sum([p for obj, p in prob_dict.items()])\n",
        "\n",
        "    def log_likelihood_exp(self, x):\n",
        "        \"\"\"Return the logarithm of the likelihood function (not including the\n",
        "        prior)\"\"\"\n",
        "        predictions = self.get_predictions(x)\n",
        "        ll = 0.\n",
        "        for measurement in self.get_measurements:\n",
        "            m_obj = flavio.Measurement[measurement]\n",
        "            m_obs = m_obj.all_parameters\n",
        "            exclude_observables = set(m_obs) - set(self.observables)\n",
        "            prob_dict = m_obj.get_logprobability_all(predictions, exclude_parameters=exclude_observables)\n",
        "            ll += sum(prob_dict.values())\n",
        "        return ll\n",
        "\n",
        "\n",
        "class BayesianFit(Fit):\n",
        "    r\"\"\"Bayesian fit class. Instances of this class can then be fed to samplers.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    - `name`: a descriptive string name\n",
        "    - `par_obj`: optional; an instance of `ParameterConstraints`.\n",
        "      Defaults to `flavio.default_parameters`\n",
        "    - `fit_parameters`: a list of string names of parameters of interest. The existing\n",
        "      constraints on the parameter will be taken as prior.\n",
        "    - `nuisance_parameters`: a list of string names of nuisance parameters. The existing\n",
        "      constraints on the parameter will be taken as prior. Alternatively, it\n",
        "      can also be set to 'all', in which case all the parameters constrainted\n",
        "      by `par_obj` will be treated as nuisance parameters. (Note that this makes\n",
        "      sense for `FastFit`, but not for a MCMC since the number of nuisance\n",
        "      parameters will be huge.)\n",
        "    - `observables`: a list of observable names to be included in the fit\n",
        "    - `exclude_measurements`: optional; a list of measurement names *not* to be included in\n",
        "    the fit. By default, all existing measurements are included.\n",
        "    - `include_measurements`: optional; a list of measurement names to be included in\n",
        "    the fit. By default, all existing measurements are included.\n",
        "    - `fit_wc_names`: optional; a list of string names of arguments of the Wilson\n",
        "      coefficient function below\n",
        "    - `fit_wc_function`: optional; a function that\n",
        "      returns a dictionary that can be fed to the `set_initial`\n",
        "      method of the Wilson coefficient class. Example: fit the real and imaginary\n",
        "      parts of $C_{10}$ in $b\\to s\\mu^+\\mu^-$.\n",
        "    ```\n",
        "    def fit_wc_function(Re_C10, Im_C10):\n",
        "        return {'C10_bsmmumu': Re_C10 + 1j*Im_C10}\n",
        "    ```\n",
        "    - `input_scale`: input scale for the Wilson coeffficients. Defaults to 160.\n",
        "    - `fit_wc_priors`: optional; an instance of WilsonCoefficientPriors\n",
        "      containing prior constraints on the Wilson coefficients\n",
        "    - `start_wc_priors`: optional; an instance of WilsonCoefficientPriors\n",
        "      that will not be used during a scan, but only for finding starting values\n",
        "      for Wilson coefficients in MCMC analyses. This can be useful if no\n",
        "      actual priors are used or if they are too loose to provide good starting\n",
        "      points.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, *args, start_wc_priors=None, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.start_wc_priors = start_wc_priors\n",
        "\n",
        "        for p in self.fit_parameters:\n",
        "            # check that fit parameters are constrained\n",
        "            assert p in self.par_obj._parameters.keys(), \"Parameter \" + p + \" not found in Constraints\"\n",
        "\n",
        "    @property\n",
        "    def get_random(self):\n",
        "        \"\"\"Get an array with random values for all the fit and nuisance\n",
        "        parameters\"\"\"\n",
        "        arr = np.zeros(self.dimension)\n",
        "        n_fit_p = len(self.fit_parameters)\n",
        "        n_nui_p = len(self.nuisance_parameters)\n",
        "        arr[:n_fit_p] = self.get_random_fit_parameters\n",
        "        arr[n_fit_p:n_fit_p+n_nui_p] = self.get_random_nuisance_parameters\n",
        "        arr[n_fit_p+n_nui_p:] = self.get_random_wilson_coeffs\n",
        "        return arr\n",
        "\n",
        "    def log_target(self, x):\n",
        "        \"\"\"Return the logarithm of the likelihood times prior probability\"\"\"\n",
        "        return self.log_likelihood_exp(x) + self.log_prior_parameters(x) + self.log_prior_wilson_coeffs(x)\n",
        "\n",
        "\n",
        "class FastFit(Fit):\n",
        "    r\"\"\"A fit class that is meant for producing fast likelihood contour plots.\n",
        "\n",
        "    Calling the method `make_measurement`, a pseudo-measurement is generated\n",
        "    that combines the actual experimental measurements with the theoretical\n",
        "    uncertainties stemming from the nuisance parameters. This is done by\n",
        "    generating random samples of the nuisance parameters and evaluating all\n",
        "    observables within the Standard Model many times (100 by default).\n",
        "    Then, the covariance of all predictions is extracted. Similarly, a covariance\n",
        "    matrix for all experimental measurements is determined. Both covariance\n",
        "    matrices are added and the resulting multivariate Gaussian treated as a\n",
        "    single measurement.\n",
        "\n",
        "    This approach has the advantage that two-dimensional plots of the likelihood\n",
        "    can be produced without the need for sampling or profiling the other\n",
        "    dimensions. However, several strong assumptions go into this method, most\n",
        "    importantly,\n",
        "\n",
        "    - all uncertainties - experimental and theoretical - are treated as Gaussian\n",
        "    - the theoretical uncertainties in the presence of new physics are assumed\n",
        "      to be equal to the ones in the SM\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.measurements = None\n",
        "        self._sm_covariance = None\n",
        "        self._exp_central_covariance = None\n",
        "        self._get_predictions_array_sm = partial(self.get_predictions_array,\n",
        "                                                 par=False, nuisance=True,\n",
        "                                                 wc=False)\n",
        "\n",
        "\n",
        "    # a method to get the mean and covariance of all measurements of all\n",
        "    # observables of interest\n",
        "    def _get_central_covariance_experiment(self, N=5000):\n",
        "        means = []\n",
        "        covariances = []\n",
        "        for measurement in self.get_measurements:\n",
        "            m_obj = flavio.Measurement[measurement]\n",
        "            # obs. included in the fit and constrained by this measurement\n",
        "            our_obs = set(m_obj.all_parameters).intersection(self.observables)\n",
        "            # construct a dict. containing a vector of N random values for\n",
        "            # each of these observables\n",
        "            random_dict = {}\n",
        "            for obs in our_obs:\n",
        "                random_dict[obs] = np.zeros(N)\n",
        "            for i in range(N):\n",
        "                m_random = m_obj.get_random_all()\n",
        "                for obs in our_obs:\n",
        "                    random_dict[obs][i] = m_random[obs]\n",
        "            # mean = np.zeros(len(self.observables))\n",
        "            random_arr = np.zeros((len(self.observables), N))\n",
        "            for i, obs in enumerate(self.observables):\n",
        "                #     n = len(random_dict[obs])\n",
        "                if obs in our_obs:\n",
        "                    random_arr[i] = random_dict[obs]\n",
        "            mean = np.mean(random_arr, axis=1)\n",
        "            covariance = np.cov(random_arr)\n",
        "            for i, obs in enumerate(self.observables):\n",
        "                if obs not in our_obs:\n",
        "                    covariance[:,i] = 0\n",
        "                    covariance[i, :] = 0\n",
        "                    covariance[i, i] = np.inf\n",
        "            means.append(mean)\n",
        "            covariances.append(covariance)\n",
        "        # if there is only a single measuement\n",
        "        if len(means) == 1:\n",
        "            if len(means[0]) == 1:\n",
        "                # if there is only a single observable\n",
        "                return means[0][0], covariances[0]\n",
        "            else:\n",
        "                return means[0], covariances[0]\n",
        "        # if there are severeal measurements, perform a weighted average\n",
        "        else:\n",
        "            # covariances: [Sigma_1, Sigma_2, ...]\n",
        "            # means: [x_1, x_2, ...]\n",
        "            # weights_ [W_1, W_2, ...] where W_i = (Sigma_i)^(-1)\n",
        "            # weighted covariance is  (W_1 + W_2 + ...)^(-1) = Sigma\n",
        "            # weigted mean is  Sigma.(W_1.x_1 + W_2.x_2 + ...) = x\n",
        "            if len(self.observables) == 1:\n",
        "                weights = np.array([1/c for c in covariances])\n",
        "                weighted_covariance = 1/np.sum(weights, axis=0)\n",
        "                weighted_mean = weighted_covariance * np.sum(\n",
        "                                [np.dot(weights[i], means[i]) for i in range(len(means))])\n",
        "            else:\n",
        "                weights = [np.linalg.inv(c) for c in covariances]\n",
        "                weighted_covariance = np.linalg.inv(np.sum(weights, axis=0))\n",
        "                weighted_mean = np.dot(weighted_covariance, np.sum(\n",
        "                                [np.dot(weights[i], means[i]) for i in range(len(means))],\n",
        "                                axis=0))\n",
        "            return weighted_mean, weighted_covariance\n",
        "\n",
        "    def get_exp_central_covariance(self, N=5000, force=True):\n",
        "        \"\"\"Return the experimental central values and the covriance matrix of\n",
        "        all observables.\n",
        "\n",
        "        Parameters:\n",
        "\n",
        "        - `N`: number of random computations (computing time is proportional\n",
        "          to it; more means less random fluctuations.)\n",
        "        - `force`: optional; if True (default), will recompute covariance even\n",
        "          if it already has been computed.\n",
        "        \"\"\"\n",
        "        if self._exp_central_covariance is None or force:\n",
        "            self._exp_central_covariance = self._get_central_covariance_experiment(N=N)\n",
        "        elif N != 5000:\n",
        "            warnings.warn(\"Argument N={} ignored \".format(N) + \\\n",
        "                          \"as experimental covariance has already been \" + \\\n",
        "                          \"computed. Recompute with get_exp_central_covariance.\")\n",
        "        return self._exp_central_covariance\n",
        "\n",
        "    def save_exp_central_covariance(self, filename):\n",
        "        \"\"\"Save the experimental central values and the covriance to a pickle\n",
        "        file.\n",
        "\n",
        "        The central values and the covariance must have been computed before\n",
        "        using `get_exp_central_covariance`.\"\"\"\n",
        "        if self._exp_central_covariance is None:\n",
        "            raise ValueError(\"Call get_exp_central_covariance or make_measurement first.\")\n",
        "        with open(filename, 'wb') as f:\n",
        "            data = dict(central=self._exp_central_covariance[0],\n",
        "                        covariance=self._exp_central_covariance[1],\n",
        "                        observables=self.observables)\n",
        "            pickle.dump(data, f)\n",
        "\n",
        "    def load_exp_central_covariance(self, filename):\n",
        "        \"\"\"Load the experimental central values and the covriance from a pickle\n",
        "        file.\"\"\"\n",
        "        with open(filename, 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "        self.load_exp_central_covariance_dict(d=data)\n",
        "\n",
        "    def load_exp_central_covariance_dict(self, d):\n",
        "        \"\"\"Load the the experimental central values and the covriancee from a\n",
        "        dictionary.\n",
        "\n",
        "        It must have the form\n",
        "        {'observables': [...], 'central': [...], 'covariance': [[...]]}\n",
        "        where 'central' is a vector of central values and 'covariance' is a\n",
        "        covariance matrix, both in the basis of observables given by\n",
        "        'observables' which must at least contain all the observables\n",
        "        involved in the fit. Additional observables will be ignored; the\n",
        "        ordering is arbitrary.\"\"\"\n",
        "        obs = d['observables']\n",
        "        try:\n",
        "            permutation = [obs.index(o) for o in self.observables]\n",
        "        except ValueError:\n",
        "            raise ValueError(\"Covariance matrix does not contain all necessary entries\")\n",
        "        assert len(permutation) == len(self.observables), \\\n",
        "            \"Covariance matrix does not contain all necessary entries\"\n",
        "        if len(permutation) == 1:\n",
        "            self._exp_central_covariance = (\n",
        "                d['central'],\n",
        "                d['covariance']\n",
        "            )\n",
        "        else:\n",
        "            self._exp_central_covariance = (\n",
        "                d['central'][permutation],\n",
        "                d['covariance'][permutation][:,permutation],\n",
        "            )\n",
        "\n",
        "    # a method to get the covariance of the SM prediction of all observables\n",
        "    # of interest\n",
        "    def _get_random_nuisance(self, *args):\n",
        "        return self._get_random(par=False, nuisance=True, wc=False)\n",
        "\n",
        "    def _get_covariance_sm(self, N=100, threads=1):\n",
        "        if threads == 1:\n",
        "            X_map = map(self._get_random_nuisance, range(N))\n",
        "            pred_map = map(self._get_predictions_array_sm, X_map)\n",
        "        else:\n",
        "            pool = Pool(threads)\n",
        "            X_map = pool.map(self._get_random_nuisance, range(N))\n",
        "            pred_map = pool.map(self._get_predictions_array_sm, X_map)\n",
        "            pool.close()\n",
        "            pool.join()\n",
        "        pred_arr = np.empty((N, len(self.observables)))\n",
        "        for i, pred_i in enumerate(pred_map):\n",
        "            pred_arr[i] = pred_i\n",
        "        return np.cov(pred_arr.T)\n",
        "\n",
        "    def get_sm_covariance(self, N=100, threads=1, force=True):\n",
        "        \"\"\"Return the covriance matrix of the SM predictions of all observables\n",
        "        under variation of all nuisance parameters.\n",
        "\n",
        "        Parameters:\n",
        "\n",
        "        - `N`: number of random computations (computing time is proportional\n",
        "          to it; more means less random fluctuations.)\n",
        "        - `threads`: optional; number of parallel threads. Defaults to 1 (no\n",
        "          parallelization)\n",
        "        - `force`: optional; if True (default), will recompute covariance even\n",
        "          if it already has been computed.\n",
        "        \"\"\"\n",
        "        if self._sm_covariance is None or force:\n",
        "            self._sm_covariance = self._get_covariance_sm(N=N, threads=threads)\n",
        "        elif N != 100:\n",
        "            warnings.warn(\"Argument N={} ignored \".format(N) + \\\n",
        "                          \"as SM covariance has already \" + \\\n",
        "                          \"been computed. Recompute with get_sm_covariance.\")\n",
        "        return self._sm_covariance\n",
        "\n",
        "    def save_sm_covariance(self, filename):\n",
        "        \"\"\"Save the SM covariance to a pickle file.\n",
        "\n",
        "        The covariance must have been computed before using\n",
        "        `get_sm_covariance`.\"\"\"\n",
        "        if self._sm_covariance is None:\n",
        "            raise ValueError(\"Call get_sm_covariance or make_measurement first.\")\n",
        "        with open(filename, 'wb') as f:\n",
        "            data = dict(covariance=self._sm_covariance,\n",
        "                        observables=self.observables)\n",
        "            pickle.dump(data, f)\n",
        "\n",
        "    def load_sm_covariance(self, filename):\n",
        "        \"\"\"Load the SM covariance from a pickle file.\"\"\"\n",
        "        with open(filename, 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "        self.load_sm_covariance_dict(d=data)\n",
        "\n",
        "    def load_sm_covariance_dict(self, d):\n",
        "        \"\"\"Load the SM covariance from a dictionary.\n",
        "\n",
        "        It must have the form {'observables': [...], 'covariance': [[...]]}\n",
        "        where 'covariance' is a covariance matrix in the basis of observables\n",
        "        given by 'observables' which must at least contain all the observables\n",
        "        involved in the fit. Additional observables will be ignored; the\n",
        "        ordering is arbitrary.\"\"\"\n",
        "        obs = d['observables']\n",
        "        try:\n",
        "            permutation = [obs.index(o) for o in self.observables]\n",
        "        except ValueError:\n",
        "            raise ValueError(\"Covariance matrix does not contain all necessary entries\")\n",
        "        assert len(permutation) == len(self.observables), \\\n",
        "            \"Covariance matrix does not contain all necessary entries\"\n",
        "        if len(permutation) == 1:\n",
        "            if d['covariance'].shape == ():\n",
        "                self._sm_covariance = d['covariance']\n",
        "            else:\n",
        "                self._sm_covariance = d['covariance'][permutation][:,permutation][0,0]\n",
        "        else:\n",
        "            self._sm_covariance = d['covariance'][permutation][:,permutation]\n",
        "\n",
        "    def make_measurement(self, N=100, Nexp=5000, threads=1, force=False, force_exp=False):\n",
        "        \"\"\"Initialize the fit by producing a pseudo-measurement containing both\n",
        "        experimental uncertainties as well as theory uncertainties stemming\n",
        "        from nuisance parameters.\n",
        "\n",
        "        Optional parameters:\n",
        "\n",
        "        - `N`: number of random computations for the SM covariance (computing\n",
        "          time is proportional to it; more means less random fluctuations.)\n",
        "        - `Nexp`: number of random computations for the experimental covariance.\n",
        "          This is much less expensive than the theory covariance, so a large\n",
        "          number can be afforded (default: 5000).\n",
        "        - `threads`: number of parallel threads for the SM\n",
        "          covariance computation. Defaults to 1 (no parallelization).\n",
        "        - `force`: if True, will recompute SM covariance even if it\n",
        "          already has been computed. Defaults to False.\n",
        "        - `force_exp`: if True, will recompute experimental central values and\n",
        "          covariance even if they have already been computed. Defaults to False.\n",
        "        \"\"\"\n",
        "        central_exp, cov_exp = self.get_exp_central_covariance(Nexp, force=force_exp)\n",
        "        cov_sm = self.get_sm_covariance(N, force=force, threads=threads)\n",
        "        covariance = cov_exp + cov_sm\n",
        "        # add the Pseudo-measurement\n",
        "        m = flavio.classes.Measurement('Pseudo-measurement for FastFit instance: ' + self.name)\n",
        "        if np.asarray(central_exp).ndim == 0 or len(central_exp) <= 1: # for a 1D (or 0D) array\n",
        "            m.add_constraint(self.observables,\n",
        "                    NormalDistribution(central_exp, np.sqrt(covariance)))\n",
        "        else:\n",
        "            m.add_constraint(self.observables,\n",
        "                    MultivariateNormalDistribution(central_exp, covariance))\n",
        "\n",
        "    def shortarray_to_dict(self, x):\n",
        "        \"\"\"Convert a 1D numpy array of floats to a dictionary of fit parameters\n",
        "        and Wilson coefficients.\"\"\"\n",
        "        d = {}\n",
        "        n_fit_p = len(self.fit_parameters)\n",
        "        n_wc = len(self.fit_wc_names)\n",
        "        d['fit_parameters'] = { p: x[i] for i, p in enumerate(self.fit_parameters) }\n",
        "        d['fit_wc'] = { p: x[i + n_fit_p] for i, p in enumerate(self.fit_wc_names) }\n",
        "        return d\n",
        "\n",
        "    def dict_to_shortarray(self, d):\n",
        "        \"\"\"Convert a dictionary of fit parameters and Wilson coefficients to a\n",
        "        1D numpy array of floats.\"\"\"\n",
        "        n_fit_p = len(self.fit_parameters)\n",
        "        n_wc = len(self.fit_wc_names)\n",
        "        arr = np.zeros(n_fit_p + n_nui_p + n_wc)\n",
        "        arr[:n_fit_p] = [d['fit_parameters'][p] for p in self.fit_parameters]\n",
        "        arr[n_fit_p:]   = [d['fit_wc'][c] for c in self.fit_wc_names]\n",
        "        return arr\n",
        "\n",
        "    def shortarray_to_array(self, x):\n",
        "        \"\"\"Convert an array of fit parameters and Wilson coefficients to an\n",
        "        array of fit parameters, nuisance parameters, and Wilson coefficients\n",
        "        (setting nuisance parameters to their central values).\"\"\"\n",
        "        n_fit_p = len(self.fit_parameters)\n",
        "        n_nui_p = len(self.nuisance_parameters)\n",
        "        n_wc = len(self.fit_wc_names)\n",
        "        arr = np.zeros(n_fit_p + n_nui_p + n_wc)\n",
        "        arr[:n_fit_p] = x[:n_fit_p]\n",
        "        arr[n_fit_p:n_fit_p+n_nui_p] = self.get_central_nuisance_parameters\n",
        "        arr[n_fit_p+n_nui_p:] = x[n_fit_p:]\n",
        "        return arr\n",
        "\n",
        "    def log_likelihood(self, x):\n",
        "        \"\"\"Return the logarithm of the likelihood. Note that there is no prior\n",
        "        probability for nuisance parameters, which have been integrated out.\n",
        "        Priors for fit parameters are ignored.\"\"\"\n",
        "         # set nuisance parameters to their central values!\n",
        "        predictions = self.get_predictions(self.shortarray_to_array(x), nuisance=False)\n",
        "        m_obj = flavio.Measurement['Pseudo-measurement for FastFit instance: ' + self.name]\n",
        "        m_obs = m_obj.all_parameters\n",
        "        prob_dict = m_obj.get_logprobability_all(predictions)\n",
        "        ll = sum(prob_dict.values())\n",
        "        return ll\n",
        "\n",
        "    def best_fit(self, **kwargs):\n",
        "        r\"\"\"Compute the best fit point in the space of fit parameters and Wilson\n",
        "        coefficients.\n",
        "\n",
        "        Keyword arguments will be passed to `scipy.optimize.minimize_scalar` in\n",
        "        the case of a single fit variable and to `flavio.math.optimize.minimize_robust`\n",
        "        in the case of multiple fit variables.\n",
        "\n",
        "        Returns a dictionary with the following keys:\n",
        "\n",
        "        - 'x': position of the best fit point\n",
        "        - 'log_likelihood': logarithm of the likelihood at the best fit point\n",
        "        \"\"\"\n",
        "        n_fit_p = len(self.fit_parameters)\n",
        "        n_wc = len(self.fit_wc_names)\n",
        "        if n_fit_p + n_wc == 1:\n",
        "            def f(x):\n",
        "                return -self.log_likelihood([x])\n",
        "            opt = scipy.optimize.minimize_scalar(f, **kwargs)\n",
        "        else:\n",
        "            def f(x):\n",
        "                return -self.log_likelihood(x)\n",
        "            if 'x0' not in kwargs:\n",
        "                x0 = np.zeros(n_fit_p + n_wc)\n",
        "                if n_fit_p > 1:\n",
        "                    x0[:n_fit_p] = self.get_central_fit_parameters\n",
        "                opt = minimize_robust(f, x0, **kwargs)\n",
        "            else:\n",
        "                opt = minimize_robust(f, **kwargs)\n",
        "        if not opt.success:\n",
        "            raise ValueError(\"Optimization failed.\")\n",
        "        else:\n",
        "            return {'x': opt.x, 'log_likelihood': -opt.fun}\n",
        "\n",
        "\n",
        "class FrequentistFit(Fit):\n",
        "    r\"\"\"Frequentist fit class.\n",
        "\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    - `name`: a descriptive string name\n",
        "    - `par_obj`: optional; an instance of `ParameterConstraints`.\n",
        "      Defaults to `flavio.default_parameters`\n",
        "    - `fit_parameters`: a list of string names of parameters of interest.\n",
        "      Existing constraints on the parameter will be ignored.\n",
        "    - `nuisance_parameters`: a list of string names of nuisance parameters. The existing\n",
        "      constraints on the parameter will be interpreted as pseudo-measurement\n",
        "      entering the likelihood.\n",
        "    - `observables`: a list of observable names to be included in the fit\n",
        "    - `exclude_measurements`: optional; a list of measurement names *not* to be included in\n",
        "    the fit. By default, all existing measurements are included.\n",
        "    - `include_measurements`: optional; a list of measurement names to be included in\n",
        "    the fit. By default, all existing measurements are included.\n",
        "    - `fit_wc_names`: optional; a list of string names of arguments of the Wilson\n",
        "      coefficient function below\n",
        "    - `fit_wc_function`: optional; a function that\n",
        "      returns a dictionary that can be fed to the `set_initial`\n",
        "      method of the Wilson coefficient class. Example: fit the real and imaginary\n",
        "      parts of $C_{10}$ in $b\\to s\\mu^+\\mu^-$.\n",
        "    ```\n",
        "    def fit_wc_function(Re_C10, Im_C10):\n",
        "        return {'C10_bsmmumu': Re_C10 + 1j*Im_C10}\n",
        "    ```\n",
        "    - `input_scale`: input scale for the Wilson coeffficients. Defaults to 160.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "    def log_likelihood(self, x):\n",
        "        \"\"\"Return the logarithm of the likelihood function (including the\n",
        "        lihelihood of nuisance parameters!)\"\"\"\n",
        "        return self.log_likelihood_exp(x) + self.log_prior_nuisance_parameters(x)"
      ]
    }
  ]
}