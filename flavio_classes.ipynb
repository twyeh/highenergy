{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAT1XEUpCffFpD5/3ZbdxK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/twyeh/highenergy/blob/main/flavio_classes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A notebook studies the flavio.classes"
      ],
      "metadata": {
        "id": "6f4oZfPJS6Le"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from .config import config\n",
        "from collections import OrderedDict, defaultdict\n",
        "import copy\n",
        "import flavio\n",
        "from flavio._parse_errors import constraints_from_string, \\\n",
        "    convolve_distributions, dict2dist\n",
        "from flavio.statistics.probability import string_to_class\n",
        "import warnings\n",
        "import yaml\n",
        "import inspect\n",
        "import urllib.parse\n",
        "import re\n",
        "import pkgutil\n"
      ],
      "metadata": {
        "id": "v0AG5AAnRgIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NamedInstanceMetaclass(type):\n",
        "    # this is just needed to implement the getitem method on NamedInstanceClass\n",
        "    # to allow the syntax MyClass['instancename'] as shorthand for\n",
        "    # MyClass.get_instance('instancename'); same for\n",
        "    # del MyClass['instancename'] instead of MyClass.del_instance('instancename')\n",
        "    def __getitem__(cls, item):\n",
        "        return cls.get_instance(item)\n",
        "\n",
        "    def __delitem__(cls, item):\n",
        "        return cls.del_instance(item)"
      ],
      "metadata": {
        "id": "t1OFM_6zSz3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NamedInstanceClass(object, metaclass=NamedInstanceMetaclass):\n",
        "    \"\"\"Base class for classes that have named instances that can be accessed\n",
        "    by their name.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "     - name: string\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "     - del_instance(name)\n",
        "         Delete an instance\n",
        "     - get_instance(name)\n",
        "         Get an instance\n",
        "     - set_description(description)\n",
        "         Set the description\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, name):\n",
        "        if not hasattr(self.__class__, 'instances'):\n",
        "            self.__class__.instances = OrderedDict()\n",
        "        self.__class__.instances[name] = self\n",
        "        self.name = name\n",
        "        self.description = ''\n",
        "\n",
        "    @classmethod\n",
        "    def get_instance(cls, name):\n",
        "        return cls.instances[name]\n",
        "\n",
        "    @classmethod\n",
        "    def del_instance(cls, name):\n",
        "        del cls.instances[name]\n",
        "\n",
        "    @classmethod\n",
        "    def clear_all(cls):\n",
        "        \"\"\"Delete all instances.\"\"\"\n",
        "        cls.instances = OrderedDict()\n",
        "\n",
        "    @classmethod\n",
        "    def find(cls, regex):\n",
        "        \"\"\"Find all instance names matching the regular expression `regex`.\"\"\"\n",
        "        rc = re.compile(regex)\n",
        "        return list(filter(rc.search, cls.instances))\n",
        "\n",
        "    def set_description(self, description):\n",
        "        self.description = description\n"
      ],
      "metadata": {
        "id": "RiD3FaKDVKbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Parameter(NamedInstanceClass):\n",
        "    \"\"\"This class holds parameters (e.g. masses and lifetimes). It requires a\n",
        "    name string and also allows to set a LaTeX name and description as\n",
        "    attributes. Note that numerical values for the Parameters are not attributes\n",
        "    of the Parameter class.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "     - name: string\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "     - tex: string\n",
        "     - description: string\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, name):\n",
        "        super().__init__(name)\n",
        "        self.tex = ''\n",
        "\n",
        "    def __repr__(self):\n",
        "        return \"Parameter('{}')\".format(self.name)\n",
        "\n",
        "    def _repr_markdown_(self):\n",
        "        md = \"### Parameter `{}`\\n\\n\".format(self.name)\n",
        "        if self.tex:\n",
        "            md += \"Parameter: {}\\n\\n\".format(self.tex)\n",
        "        if self.description:\n",
        "            md += \"Description: {}\\n\\n\".format(self.description)\n",
        "        return md"
      ],
      "metadata": {
        "id": "Wf-de7fkde4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Constraints(object):\n",
        "    \"\"\"Constraints are collections of probability distributions associated\n",
        "    to objects like parameters or measurements. This is the base class of\n",
        "    ParameterConstraints (that holds the numerical values and uncertainties\n",
        "    of all the parameters) and Measurements (that holds the numerical values\n",
        "    and uncertainties of all the experimental measurements.)\n",
        "\n",
        "    Since this class is not meant for direct use, see these child classes for\n",
        "    documentation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "            # Here we have two data structures. _constraints has the form\n",
        "            # [ (<constraint1>, [parameter1, parameter2, ...]), (<constraint2>, ...) ]\n",
        "            # where the <constraint>s are instances of ProbabilityDistribution\n",
        "            # and the parameters string names, while _parameters has the form\n",
        "            # { parameter1: (num1, <constraint1>)} where num1 is 0 for a\n",
        "            # univariate constraint and otherwise gives the position of\n",
        "            # parameter1 in the multivariate vector.\n",
        "            # In summary, having this list and dictionary allow a bijective mapping between\n",
        "            # constraints and parameters.\n",
        "            # Note that one constraint can apply to multiple parameters (e.g.\n",
        "            # in case of correlated uncertainties), but a parameter can only\n",
        "            # have a single constraint (changed in v0.16!).\n",
        "        self._constraints = []\n",
        "        self._parameters = OrderedDict()\n",
        "\n",
        "    @property\n",
        "    def all_parameters(self):\n",
        "        \"\"\"Returns a list of all parameters/observables constrained.\"\"\"\n",
        "        return list(self._parameters.keys())\n",
        "\n",
        "    def add_constraint(self, parameters, constraint, is_parameter_constraint=None):\n",
        "        \"\"\"Set the constraint on one or several parameters/observables.\n",
        "\n",
        "        `constraint` must be an instance of a child of ProbabilityDistribution.\n",
        "\n",
        "        Note that if there already exists a constraint, it will be removed.\"\"\"\n",
        "        for num, parameter in enumerate(parameters):\n",
        "            if is_parameter_constraint:\n",
        "                try: # check if parameter object already exists\n",
        "                    p = Parameter[parameter]\n",
        "                except: # otherwise, create a new one\n",
        "                    p = Parameter(parameter)\n",
        "                else: # if parameter exists, remove existing constraints\n",
        "                    self.remove_constraint(parameter)\n",
        "            # remove constraint if there is one\n",
        "            if parameter in self._parameters:\n",
        "                self.remove_constraint(parameter)\n",
        "        # populate the dictionaries defined in __init__\n",
        "            self._parameters[parameter] = (num, constraint)\n",
        "        self._constraints.append((constraint, parameters))\n",
        "\n",
        "    def set_constraint(self, parameter, constraint_string=None,constraint_dict=None):\n",
        "        r\"\"\"Set the constraint on a parameter/observable by specifying a string\n",
        "        or a dictionary. If several constraints (e.g. several types of\n",
        "        uncertainty) are given, the total constraint will be the convolution\n",
        "        of the individual distributions. Existing constraints will be removed.\n",
        "\n",
        "        Arguments:\n",
        "\n",
        "        - parameter: parameter string (or tuple)\n",
        "        - constraint_string: string specifying the constraint that can be e.g.\n",
        "          of the form `'1.55(3)(1)'` or `'4.0±0.1'`.\n",
        "        - constraint_dict: dictionary or list of several dictionaries of the\n",
        "          form `{'distribution': 'distribution_name', 'arg1': val1, ...}`, where\n",
        "          'distribution_name' is a string name associated to each probability\n",
        "          distribution (see `flavio.statistics.probability.class_from_string`)\n",
        "          and `'arg1'`, `val1` are argument/value pairs of the arguments of\n",
        "          the distribution class's constructor (e.g.`central_value`,\n",
        "          `standard_deviation` for a normal distribution).\n",
        "\n",
        "        `constraint_string` and `constraint_dict` must not be present\n",
        "        simultaneously.\n",
        "        \"\"\"\n",
        "        if constraint_string is not None and constraint_dict is not None:\n",
        "            raise ValueError(\"constraint_string and constraint_dict cannot\"\n",
        "                             \" be used at the same time.\")\n",
        "        if constraint_string is not None:\n",
        "            pds = constraints_from_string(constraint_string)\n",
        "        elif constraint_dict is not None:\n",
        "            pds = dict2dist(constraint_dict)\n",
        "        else:\n",
        "            raise TypeError(\"Either constraint_string or constraint_dict have\"\n",
        "                            \" to be specified.\")\n",
        "        combined_pd = convolve_distributions(pds)\n",
        "        self.add_constraint([parameter], combined_pd)\n",
        "\n",
        "    def remove_constraint(self, parameter):\n",
        "        \"\"\"Remove existing constraint on a parameter.\"\"\"\n",
        "        self._parameters.pop(parameter, None)\n",
        "\n",
        "    def remove_constraints(self, parameter):\n",
        "        warnings.warn(\"This function was renamed to `remove_constraint` \"\n",
        "                      \"in v0.16 and will be removed in the future.\",\n",
        "                      DeprecationWarning)\n",
        "        self.remove_constraint(parameter)\n",
        "\n",
        "    def get_central(self, parameter):\n",
        "        \"\"\"Get the central value of a parameter\"\"\"\n",
        "        if parameter not in self._parameters.keys():\n",
        "            raise ValueError('No constraints applied to parameter/observable ' + parameter)\n",
        "        else:\n",
        "            num, constraint = self._parameters[parameter]\n",
        "            cv = constraint.central_value\n",
        "            try:\n",
        "                cv = float(cv)\n",
        "            except (TypeError, ValueError):\n",
        "                # return the num-th entry of the central value vector\n",
        "                return cv[num]\n",
        "            else:\n",
        "                if num == 0:\n",
        "                    return cv\n",
        "                else:\n",
        "                    raise ValueError(\"Something went wrong when getting the central value of {}\".format(parameter))\n",
        "\n",
        "    def get_central_all(self):\n",
        "        \"\"\"Get central values of all constrained parameters.\"\"\"\n",
        "        return {parameter: self.get_central(parameter) for parameter in self._parameters.keys()}\n",
        "\n",
        "    def get_random_all(self, size=None):\n",
        "        \"\"\"Get random values for all constrained parameters where they are\n",
        "        distributed according to the probability distribution applied.\n",
        "\n",
        "        If `size` is not None, the dictionary values will be arrays with length\n",
        "        `size` rather than numbers.\"\"\"\n",
        "        # first, generate random values for every single one of the constraints\n",
        "        random_constraints = {constraint: constraint.get_random(size=size)\n",
        "                              for constraint, _ in self._constraints}\n",
        "        random_dict = {}\n",
        "        # now, iterate over the parameters\n",
        "        for parameter, constraints in self._parameters.items():\n",
        "            num, constraint = constraints\n",
        "            carr = random_constraints[constraint]\n",
        "            if size is None and num == 0 and np.isscalar(carr):\n",
        "                random_dict[parameter] = carr\n",
        "            elif size is None and num == 0 and carr.shape == tuple():\n",
        "                random_dict[parameter] = carr\n",
        "            elif size is None:\n",
        "                random_dict[parameter] = carr[num]\n",
        "            elif carr.shape == (size,) and num == 0:\n",
        "                random_dict[parameter] = carr\n",
        "            elif carr.ndim == 2 and carr.shape[0] == size:\n",
        "                random_dict[parameter] = carr[:, num]\n",
        "            else:\n",
        "                raise ValueError(\"Unexpected error in get_random_all\")\n",
        "        return random_dict\n",
        "\n",
        "    def get_1d_errors(self, N=1000):\n",
        "        warnings.warn(\"This function was renamed to `get_1d_errors_random` \"\n",
        "                      \"in v0.16 and will be removed in the future. \",\n",
        "                      DeprecationWarning)\n",
        "        self.get_1d_errors_random(N)\n",
        "\n",
        "    def get_1d_errors_random(self, N=1000):\n",
        "        \"\"\"Get the Gaussian standard deviation for every parameter/observable\n",
        "        obtained by generating N random values.\"\"\"\n",
        "        random_dict_list = [self.get_random_all() for i in range(N)]\n",
        "        interval_dict = {}\n",
        "        for k in random_dict_list[0].keys():\n",
        "            arr = np.array([r[k] for r in random_dict_list])\n",
        "            interval_dict[k] = np.std(arr)\n",
        "        return interval_dict\n",
        "\n",
        "    def get_1d_errors_rightleft(self):\n",
        "        r\"\"\"Get the left and right error for every parameter/observable\n",
        "        defined such that it contains 68% probability on each side of the\n",
        "        central value.\"\"\"\n",
        "        errors_left = [constraint.error_left for constraint, _ in self._constraints]\n",
        "        errors_right = [constraint.error_right for constraint, _ in self._constraints]\n",
        "        error_dict = {}\n",
        "        # now, iterate over the parameters\n",
        "        for parameter, constraints in self._parameters.items():\n",
        "            num, constraint = constraints\n",
        "            idx = ([constraint for constraint, _ in self._constraints]).index(constraint)\n",
        "            error_dict[parameter] = (np.ravel([errors_right[idx]])[num],\n",
        "                                     np.ravel([errors_left[idx]])[num])\n",
        "        return error_dict\n",
        "\n",
        "    def get_logprobability_single(self, parameter, value, delta=False):\n",
        "        \"\"\"Return a dictionary with the logarithm of the probability for each\n",
        "        constraint/probability distribution for a given value of a\n",
        "        single parameter.\n",
        "        \"\"\"\n",
        "        num, constraint = self._parameters[parameter]\n",
        "        parameters = OrderedDict(self._constraints)[constraint]\n",
        "        if len(parameters) == 1:\n",
        "            if not delta:\n",
        "                return constraint.logpdf(value)\n",
        "            else:\n",
        "                return constraint.delta_logpdf(value)\n",
        "        else:\n",
        "            # for multivariate distributions\n",
        "            exclude = tuple(i for i, p in enumerate(parameters)\n",
        "                            if p != parameter)\n",
        "            if not delta:\n",
        "                return constraint.logpdf([value], exclude=exclude)\n",
        "            else:\n",
        "                return constraint.delta_logpdf([value], exclude=exclude)\n",
        "\n",
        "    def get_logprobability_all(self, par_dict, exclude_parameters=[], delta=False):\n",
        "        \"\"\"Return a dictionary with the logarithm of the probability for each\n",
        "        constraint/probability distribution.\n",
        "\n",
        "        Inputs\n",
        "        ------\n",
        "        - par_dict\n",
        "          A dictionary of the form {parameter: value, ...} where parameter\n",
        "          is a string and value a float.\n",
        "        - exclude_parameters (optional)\n",
        "          An iterable of strings (default: empty) that specifies parameters\n",
        "          that should be ignored. Univariate constraints on this parameter\n",
        "          will be skipped, while for multivariate normally distributed\n",
        "          constraints, the parameter will be removed from the covariance.\n",
        "        \"\"\"\n",
        "        prob_dict = {}\n",
        "        for constraint, parameters in self._constraints:\n",
        "            # list of constrained parameters except the excluded ones\n",
        "            p_cons = [p for p in parameters\n",
        "                      if (p not in exclude_parameters\n",
        "                      and (parameters.index(p), constraint) == self._parameters.get(p, None))]\n",
        "            x = [par_dict[p] for p in p_cons]\n",
        "            if not x:\n",
        "                # nothing to constrain\n",
        "                continue\n",
        "            if len(parameters) == 1:\n",
        "                # 1D constraints should have a scalar, not a length-1 array\n",
        "                if not delta:\n",
        "                    prob_dict[constraint] = constraint.logpdf(x[0])\n",
        "                else:\n",
        "                    prob_dict[constraint] = constraint.delta_logpdf(x[0])\n",
        "            else:\n",
        "                # for multivariate distributions\n",
        "                if len(x) == len(parameters):\n",
        "                    # no parameter has been excluded\n",
        "                    exclude = None\n",
        "                else:\n",
        "                    exclude = tuple(i for i, p in enumerate(parameters)\n",
        "                                    if p not in p_cons)\n",
        "                if not delta:\n",
        "                    prob_dict[constraint] = constraint.logpdf(x, exclude=exclude)\n",
        "                else:\n",
        "                    prob_dict[constraint] = constraint.delta_logpdf(x, exclude=exclude)\n",
        "        return prob_dict\n",
        "\n",
        "    def copy(self):\n",
        "        # this is to have a .copy() method like for a dictionary\n",
        "        return copy.deepcopy(self)\n",
        "\n",
        "    def get_yaml(self, *args, **kwargs):\n",
        "        \"\"\"Get a YAML string representation of all constraints.\n",
        "\n",
        "        The optional parameter `pname` allows to customize the name of the key\n",
        "        containing the parameter list of each constraint (e.g. 'parameters',\n",
        "        'observables').\n",
        "        \"\"\"\n",
        "        return yaml.dump(self.get_yaml_dict(*args, **kwargs))\n",
        "\n",
        "    def get_yaml_dict(self, pname='parameters'):\n",
        "        \"\"\"Get an ordered dictionary representation of all constraints that can\n",
        "        be dumped as YAML string.\n",
        "\n",
        "        The optional parameter `pname` allows to customize the name of the key\n",
        "        containing the parameter list of each constraint (e.g. 'parameters',\n",
        "        'observables').\n",
        "        \"\"\"\n",
        "        data = []\n",
        "        for constraint, parameters in self._constraints:\n",
        "            d = OrderedDict()\n",
        "            d[pname] = [list(p) if isinstance(p, tuple) else p for p in parameters]\n",
        "            d['values'] = constraint.get_dict(distribution=True,\n",
        "                                              iterate=True, arraytolist=True)\n",
        "            data.append(d)\n",
        "        args = inspect.signature(self.__class__).parameters.keys()\n",
        "        meta = {k: v for k, v in self.__dict__.items()\n",
        "                if k[0] != '_' and v != '' and k not in args}\n",
        "        if not args and not meta:\n",
        "            return data\n",
        "        else:\n",
        "            datameta = OrderedDict()\n",
        "            if args:\n",
        "                datameta['arguments'] = {arg: self.__dict__[arg] for arg in args}\n",
        "            if meta:\n",
        "                datameta['metadata'] = meta\n",
        "            datameta['constraints'] = data\n",
        "            return datameta\n",
        "\n",
        "    @classmethod\n",
        "    def from_yaml(cls, stream, *args, **kwargs):\n",
        "        \"\"\"Class method: load constraint from a YAML string or stream.\"\"\"\n",
        "        data = yaml.safe_load(stream)\n",
        "        return cls.from_yaml_dict(data, *args, **kwargs)\n",
        "\n",
        "    @classmethod\n",
        "    def from_yaml_dict(cls, data, pname='parameters', instance=None, *args, **kwargs):\n",
        "        \"\"\"Class method: load constraint from a dictionary or list of dicts.\n",
        "\n",
        "        If it is a dictionary, it should have the form:\n",
        "\n",
        "        ```{\n",
        "        'metadata': {...},  # optional, do set attributes of the instance\n",
        "        'arguments': {...},  # optional, to specify keyword arguments for instantiation,\n",
        "        'constraints': [...],  # required, the list of constraints\n",
        "        }\n",
        "\n",
        "        Alternatively, the list of constraints can be directly given.\n",
        "        This list should have elements in one of the two possible forms:\n",
        "\n",
        "        1. Dictionary as returned by `Probability.get_dict`:\n",
        "        ```{\n",
        "        pname: [...],  # required, list of constrained parameters\n",
        "        'values': {\n",
        "            'distribution': '...',  # required, string identifying ProbabilityDistribution, e.g. 'normal'\n",
        "            '...': '...',  # required, any arguments for the instantiation of the ProbabilityDistribution\n",
        "            }\n",
        "        }\n",
        "        ```\n",
        "\n",
        "        2. String representing one or several (to be convolved) constraints:\n",
        "        ```{\n",
        "        'my_parameter': '1.0 ± 0.2 ± 0.1 e-3'\n",
        "        }\n",
        "        \"\"\"\n",
        "        if isinstance(data, dict):\n",
        "            constraints = data['constraints']\n",
        "            meta = data.get('metadata', {})\n",
        "            arguments = data['arguments']\n",
        "            kwargs.update(arguments)\n",
        "            inst = instance or cls(*args, **kwargs)\n",
        "            for m in meta:\n",
        "                inst.__dict__[m] = meta[m]\n",
        "        else:\n",
        "            inst = instance or cls(*args, **kwargs)\n",
        "            constraints = data.copy()\n",
        "        for c in constraints:\n",
        "            if pname not in c:\n",
        "                if 'values' not in c and len(c) == 1:\n",
        "                    # this means we probably have a constraint of the\n",
        "                    # form parameter: constraint_string\n",
        "                    for k, v in c.items():  # this loop runs only once\n",
        "                        inst.set_constraint(k, v)\n",
        "                        break  # just to be sure\n",
        "                    continue\n",
        "                else:\n",
        "                    # in this case something is clearly wrong. Mabye the\n",
        "                    # wrong \"pname\" was used.\n",
        "                    raise ValueError('Key ' + pname + ' not found. '\n",
        "                                     'Please check the `pname` argument.')\n",
        "            else:\n",
        "                parameters = [tuple(p) if isinstance(p, list) else p for p in c[pname]]\n",
        "                pds = dict2dist(c['values'])\n",
        "                combined_pd = convolve_distributions(pds)\n",
        "                inst.add_constraint(parameters, combined_pd)\n",
        "        return inst\n"
      ],
      "metadata": {
        "id": "z04wCIG69VZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ParameterConstraints(Constraints):\n",
        "    \"\"\"Trivial subclass of `Constraints` that is meant for constraints on\n",
        "    theory parameters represented by instances of the `Parameter` class.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def read_default(self):\n",
        "        \"\"\"Reset the instance and read the default parameters. Data is read\n",
        "        - from 'data/parameters_metadata.yml'\n",
        "        - from 'data/parameters_uncorrelated.yml'\n",
        "        - from 'data/parameters_correlated.yml'\n",
        "        - from the default PDG data file\n",
        "        - for B->V form factors\n",
        "        - for B->P form factors\n",
        "        - for Lambdab->Lambda form factors\n",
        "        \"\"\"\n",
        "        # import functions to read parameters\n",
        "        from flavio.parameters import (\n",
        "            _read_yaml_object_metadata,\n",
        "            _read_yaml_object_values,\n",
        "            _read_yaml_object_values_correlated,\n",
        "            read_pdg\n",
        "        )\n",
        "\n",
        "        # reset the instance\n",
        "        self.__init__()\n",
        "\n",
        "        # Read the parameter metadata from the default YAML data file\n",
        "        _read_yaml_object_metadata(pkgutil.get_data('flavio', 'data/parameters_metadata.yml'), self)\n",
        "\n",
        "        # Read the uncorrelated parameter values from the default YAML data file\n",
        "        _read_yaml_object_values(pkgutil.get_data('flavio', 'data/parameters_uncorrelated.yml'), self)\n",
        "\n",
        "        # Read the correlated parameter values from the default YAML data file\n",
        "        _read_yaml_object_values_correlated(pkgutil.get_data('flavio', 'data/parameters_correlated.yml'), self)\n",
        "\n",
        "        # Read the parameters from the default PDG data file\n",
        "        read_pdg(2022, self)\n",
        "\n",
        "        # Read default parameters for B->V form factors\n",
        "        flavio.physics.bdecays.formfactors.b_v.bsz_parameters.bsz_load('v2', 'LCSR', ('B->omega', 'B->rho'), self)\n",
        "        flavio.physics.bdecays.formfactors.b_v.bsz_parameters.bsz_load('v2', 'LCSR-Lattice', ('B->K*', 'Bs->phi', 'Bs->K*'), self)\n",
        "\n",
        "        # Read default parameters for B->P form factors\n",
        "        flavio.physics.bdecays.formfactors.b_p.bsz_parameters.load_ffs_eos('data/arXiv-2305-06301v1/BSZ-parameters-N2.yaml', 'B->K::FormFactors[parametric,BSZ]@GRvDV:2023A', r'::alpha\\^(.*)_(.*)@BSZ2015', r' BSZ a\\2_\\1', self) # B->K\n",
        "        flavio.physics.bdecays.formfactors.b_p.bcl_parameters_lmvd.load_parameters('data/arXiv-2102.07233v2/LCSR-LQCD_mod_BCL_params_K=4.yaml', self) # B->pi\n",
        "\n",
        "        # Read default parameters for Lambdab->Lambda form factors\n",
        "        flavio.physics.bdecays.formfactors.lambdab_12.lattice_parameters.lattice_load_ho(self)\n"
      ],
      "metadata": {
        "id": "9ojOztdC9qCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WilsonCoefficientPriors(Constraints):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "def tree():\n",
        "    \"\"\"Tree data structure.\n",
        "\n",
        "    See https://gist.github.com/hrldcpr/2012250\"\"\"\n",
        "    return defaultdict(tree)\n",
        "\n",
        "\n",
        "def dicts(t):\n",
        "    \"\"\"Turn tree into nested dict\"\"\"\n",
        "    return {k: dicts(t[k]) for k in t}\n"
      ],
      "metadata": {
        "id": "_k6EgIpq98t-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Observable(NamedInstanceClass):\n",
        "    \"\"\"An Observable is something that can be measured experimentally and\n",
        "    predicted theoretically.\"\"\"\n",
        "\n",
        "    def __init__(self, name, arguments=None):\n",
        "        super().__init__(name)\n",
        "        if not hasattr(self.__class__, 'taxonomy'):\n",
        "            self.__class__.taxonomy = tree()\n",
        "        self.arguments = arguments\n",
        "        self.prediction = None\n",
        "        self.tex = ''\n",
        "\n",
        "    def __repr__(self):\n",
        "        return \"Observable('{}', arguments={})\".format(self.name, self.arguments)\n",
        "\n",
        "    def _repr_markdown_(self):\n",
        "        md = \"### Observable `{}`\\n\\n\".format(self.name)\n",
        "        if self.tex:\n",
        "            md += \"Observable: {}\\n\\n\".format(self.tex)\n",
        "        if self.description:\n",
        "            md += \"Description: {}\\n\\n\".format(self.description)\n",
        "        if self.arguments is not None:\n",
        "            md += \"Arguments: \"\n",
        "            md += ','.join([\"`{}`\".format(a) for a in self.arguments])\n",
        "            md += \"\\n\\n\"\n",
        "        if self.prediction is not None:\n",
        "            f = self.prediction.function\n",
        "            from IPython.lib import pretty\n",
        "            md += \"Theory prediction: `{}`\".format(pretty.pretty(f))\n",
        "        return md\n",
        "\n",
        "    @classmethod\n",
        "    def argument_format(cls, obs, format='tuple'):\n",
        "        \"\"\"Class method: takes as input an observable name and numerical values\n",
        "        for the arguements (if any) and returns as output the same in a specific\n",
        "        form as specified by `format`: 'tuple' (default), 'list', or 'dict'.\n",
        "\n",
        "        Example inputs:\n",
        "        - ('dBR/dq2(B0->Denu)', 1)\n",
        "        - {'name': 'dBR/dq2(B0->Denu)', 'q2': 1}\n",
        "\n",
        "        Output:\n",
        "        tuple: ('dBR/dq2(B0->Denu)', 1)\n",
        "        list: ('dBR/dq2(B0->Denu)', 1)\n",
        "        dict: {'name': 'dBR/dq2(B0->Denu)', 'q2': 1}\n",
        "\n",
        "        For a string input for observables that don't have arguments:\n",
        "        - 'eps_K'\n",
        "\n",
        "        Output:\n",
        "        tuple: 'eps_K'\n",
        "        list: 'eps_K'\n",
        "        dict: {'name': 'eps_K'}\n",
        "        \"\"\"\n",
        "        if isinstance(obs, str):\n",
        "            if cls[obs].arguments is not None:\n",
        "                raise ValueError(\"Arguments missing for {}\".format(obs))\n",
        "            if format == 'dict':\n",
        "                return {'name': obs}\n",
        "            else:\n",
        "                return obs\n",
        "        elif isinstance(obs, (tuple, list)):\n",
        "            args = cls[obs[0]].arguments\n",
        "            if args is None or len(args) != len(obs) - 1:\n",
        "                raise ValueError(\"Wrong number of arguments for {}\".format(obs[0]))\n",
        "            t = tuple(obs)\n",
        "            d = {'name': obs[0]}\n",
        "            for i, a in enumerate(args):\n",
        "                d[a] = obs[i + 1]\n",
        "        elif isinstance(obs, dict):\n",
        "            args = cls[obs['name']].arguments\n",
        "            if args is None:\n",
        "                t = obs['name']\n",
        "            else:\n",
        "                t = tuple([obs['name']] + [obs[a] for a in args])\n",
        "            d = obs\n",
        "        if format == 'tuple':\n",
        "            return t\n",
        "        elif format == 'list':\n",
        "            return list(t)\n",
        "        elif format == 'dict':\n",
        "            return d\n",
        "\n",
        "    def set_prediction(self, prediction):\n",
        "        self.prediction = prediction\n",
        "\n",
        "    def prediction_central(self, constraints_obj, wc_obj, *args, **kwargs):\n",
        "        return self.prediction.get_central(constraints_obj, wc_obj, *args, **kwargs)\n",
        "\n",
        "    def prediction_par(self, par_dict, wc_obj, *args, **kwargs):\n",
        "        return self.prediction.get_par(par_dict, wc_obj, *args, **kwargs)\n",
        "\n",
        "    def add_taxonomy(self, taxonomy_string):\n",
        "        \"\"\"Add a metadata taxonomy for the observable.\n",
        "\n",
        "        `taxonomy_string` has to be a string of the form\n",
        "        'Category :: Subcategory :: Subsubcategory'\n",
        "        etc. LaTeX code is allowed. One observable can also have multiple\n",
        "        taxonomies (e.g. 'Animal :: Cat' and 'Pet :: Favourite Pet')\"\"\"\n",
        "        taxonomy_list = taxonomy_string.split(' :: ') + [self.name]\n",
        "        t = self.__class__.taxonomy\n",
        "        for node in taxonomy_list:\n",
        "            t = t[node]\n",
        "\n",
        "    @classmethod\n",
        "    def taxonomy_dict(cls):\n",
        "        \"\"\"Return the hierarchical metadata taxonomy as a nested dictionary.\"\"\"\n",
        "        return dicts(cls.taxonomy)\n",
        "\n",
        "    @classmethod\n",
        "    def from_function(cls, name, observables, function):\n",
        "        \"\"\"Instantiate an observable object and the corresponding Prediction\n",
        "        object for an observable that is defined as a mathematical function\n",
        "        of two or more existing observables with existing predictions.\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "\n",
        "        - name: string name of the new observable\n",
        "        - observables: list of string names of the observables to be combined\n",
        "        - function: function of the observables. The number of arguments must\n",
        "          match the number of observables\n",
        "\n",
        "        Example:\n",
        "        --------\n",
        "\n",
        "        For two existing observables 'my_obs_1' and 'my_obs_2', a new observable\n",
        "        that is defined as the difference between the two can be defined as\n",
        "\n",
        "        ```\n",
        "        Observable.from_function('my_obs_1_2_diff',\n",
        "                                 ['my_obs_1', 'my_obs_2'],\n",
        "                                 lambda x, y: x - y)\n",
        "        ```\n",
        "        \"\"\"\n",
        "        for observable in observables:\n",
        "            try:\n",
        "                Observable[observable]\n",
        "            except KeyError:\n",
        "                raise ValueError(\"The observable \" + observable + \" does not exist\")\n",
        "            assert Observable[observable].arguments == Observable[observables[0]].arguments, \\\n",
        "                \"Only observables depending on the same arguments can be combined\"\n",
        "            assert Observable[observable].prediction is not None, \\\n",
        "                \"The observable {} does not have a prediction yet\".format(observable)\n",
        "        obs_obj = cls(name, arguments=Observable[observables[0]].arguments)\n",
        "        pfcts = [Observable[observable].prediction.function\n",
        "                 for observable in observables]\n",
        "        def pfct(*args, **kwargs):\n",
        "            return function(*[f(*args, **kwargs) for f in pfcts])\n",
        "        Prediction(name, pfct)\n",
        "        return obs_obj\n",
        "\n",
        "    def get_measurements(self):\n",
        "        r\"\"\"Return the names of measurements that constrain the observable.\"\"\"\n",
        "        ms = []\n",
        "        for name, m in Measurement.instances.items():\n",
        "            if self.name in m.all_parameters:\n",
        "                ms.append(name)\n",
        "            else:\n",
        "                for obs in m.all_parameters:\n",
        "                    if isinstance(obs, tuple):\n",
        "                        if obs[0] == self.name:\n",
        "                            ms.append(name)\n",
        "                            break\n",
        "        return ms\n",
        "\n",
        "    def theory_citations(self, *args, **kwargs):\n",
        "        \"\"\"Return a set of theory papers (in the form of INSPIRE texkeys) to\n",
        "        cite for the theory prediction for an observable.\n",
        "\n",
        "        Arguments are passed to the observable and are necessary,\n",
        "        depending on the observable (e.g. $q^2$-dependent observables).\n",
        "        \"\"\"\n",
        "        with flavio.citations.collect() as citations:\n",
        "            flavio.sm_prediction(self.name, *args, **kwargs)\n",
        "        return citations.set\n",
        "\n"
      ],
      "metadata": {
        "id": "VyvrQoIM-DSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AuxiliaryQuantity(NamedInstanceClass):\n",
        "    \"\"\"An auxiliary quantity is something that can be computed theoretically but\n",
        "    not measured directly, e.g. some sub-contribution to an amplitude or a form\n",
        "    factor.\"\"\"\n",
        "\n",
        "    def __init__(self, name, arguments=None):\n",
        "        super().__init__(name)\n",
        "        self.arguments = arguments\n",
        "\n",
        "    def get_implementation(self):\n",
        "        try:\n",
        "            implementation_name = config['implementation'][self.name]\n",
        "        except KeyError:\n",
        "            raise KeyError(\"No implementation specified for auxiliary quantity \" + self.name)\n",
        "        return Implementation[implementation_name]\n",
        "\n",
        "    def prediction_central(self, constraints_obj, wc_obj, *args, **kwargs):\n",
        "        implementation = self.get_implementation()\n",
        "        return implementation.get_central(constraints_obj, wc_obj, *args, **kwargs)\n",
        "\n",
        "    def prediction(self, par_dict, wc_obj, *args, **kwargs):\n",
        "        implementation = self.get_implementation()\n",
        "        return implementation.get(par_dict, wc_obj, *args, **kwargs)\n",
        "\n"
      ],
      "metadata": {
        "id": "7Xk326Vw-PVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Prediction(object):\n",
        "    \"\"\"A prediction is the theoretical prediction for an observable.\"\"\"\n",
        "\n",
        "    def __init__(self, observable, function):\n",
        "        try:\n",
        "            Observable[observable]\n",
        "        except KeyError:\n",
        "            raise ValueError(\"The observable \" + observable + \" does not exist\")\n",
        "        self.observable = observable\n",
        "        self.function = function\n",
        "        self.observable_obj = Observable[observable]\n",
        "        self.observable_obj.set_prediction(self)\n",
        "\n",
        "    def get_central(self, constraints_obj, wc_obj, *args, **kwargs):\n",
        "        par_dict = constraints_obj.get_central_all()\n",
        "        fwc_obj = flavio.WilsonCoefficients.from_wilson(wc_obj, par_dict)\n",
        "        return self.function(fwc_obj, par_dict, *args, **kwargs)\n",
        "\n",
        "    def get_par(self, par_dict, wc_obj, *args, **kwargs):\n",
        "        fwc_obj = flavio.WilsonCoefficients.from_wilson(wc_obj, par_dict)\n",
        "        return self.function(fwc_obj, par_dict, *args, **kwargs)\n",
        "\n"
      ],
      "metadata": {
        "id": "5RX6olhf-Tkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Implementation(NamedInstanceClass):\n",
        "    \"\"\"An implementation is the theoretical prediction for an auxiliary\n",
        "    quantity.\"\"\"\n",
        "\n",
        "    @classmethod\n",
        "    def show_all(cls):\n",
        "        all_dict = {}\n",
        "        for name in cls.instances:\n",
        "            inst = cls[name]\n",
        "            quant = inst.quantity\n",
        "            descr = inst.description\n",
        "            all_dict[quant] = {name: descr}\n",
        "        return all_dict\n",
        "\n",
        "    def __init__(self, name, quantity, function):\n",
        "        super().__init__(name)\n",
        "        try:\n",
        "            AuxiliaryQuantity[quantity]\n",
        "        except KeyError:\n",
        "            raise ValueError(\"The quantity \" + quantity + \" does not exist\")\n",
        "        self.quantity = quantity\n",
        "        self.function = function\n",
        "        self.quantity_obj = AuxiliaryQuantity[quantity]\n",
        "\n",
        "    def get_central(self, constraints_obj, wc_obj, *args, **kwargs):\n",
        "        par_dict = constraints_obj.get_central_all()\n",
        "        fwc_obj = flavio.WilsonCoefficients.from_wilson(wc_obj, par_dict)\n",
        "        return self.function(fwc_obj, par_dict, *args, **kwargs)\n",
        "\n",
        "    def get_random(self, constraints_obj, wc_obj, *args, **kwargs):\n",
        "        par_dict = constraints_obj.get_random_all()\n",
        "        fwc_obj = flavio.WilsonCoefficients.from_wilson(wc_obj, par_dict)\n",
        "        return self.function(fwc_obj, par_dict, *args, **kwargs)\n",
        "\n",
        "    def get(self, par_dict, wc_obj, *args, **kwargs):\n",
        "        fwc_obj = flavio.WilsonCoefficients.from_wilson(wc_obj, par_dict)\n",
        "        return self.function(fwc_obj, par_dict, *args, **kwargs)\n"
      ],
      "metadata": {
        "id": "qW653I1q-YuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPLnp0G4jbKL"
      },
      "outputs": [],
      "source": [
        "class Measurement(Constraints, NamedInstanceClass):\n",
        "    \"\"\"A (experimental) measurement associates one (or several) probability\n",
        "    distributions to one (or several) observables. If it contains several\n",
        "    observables, these can (but do not have to) be correlated.\n",
        "\n",
        "    To instantiate the class, call Measurement(name) with a string uniquely\n",
        "    describing the measurement (e.g. 'CMS Bs->mumu 2012').\n",
        "\n",
        "    To add a constraint (= central vaue(s) and uncertainty(s)), use\n",
        "\n",
        "    `add_constraint(observables, constraint)`\n",
        "\n",
        "    where `constraint` is an instance of a descendant of\n",
        "    ProbabilityDistribution and `observables` is a list of either\n",
        "     - a string observable name in the case of observables without arguments\n",
        "     - or a tuple `(name, x_1, ..., x_n)`, where the `x_i` are float values for\n",
        "       the arguments, of an observable with `n` arguments.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, name):\n",
        "        NamedInstanceClass.__init__(self, name)\n",
        "        Constraints.__init__(self)\n",
        "        self.inspire = ''\n",
        "        self.experiment = ''\n",
        "        self.url = ''\n",
        "\n",
        "    def __repr__(self):\n",
        "        return \"Measurement('{}')\".format(self.name)\n",
        "\n",
        "    def _repr_markdown_(self):\n",
        "        md = \"### Measurement `{}`\\n\\n\".format(self.name)\n",
        "        if self.experiment:\n",
        "            md += \"Experiment: {}\\n\\n\".format(self.experiment)\n",
        "        if self.inspire:\n",
        "            md += (\"[Inspire](http://inspirehep.net/search?&p=texkey+{})\\n\\n\"\n",
        "                   .format(urllib.parse.quote(self.inspire)))\n",
        "        if self.url:\n",
        "            md += \"URL: <{}>\\n\\n\".format(self.url)\n",
        "        if self.description:\n",
        "            md += \"Description: {}\\n\\n\".format(self.description)\n",
        "        if self.all_parameters:\n",
        "            md += \"Measured observables:\\n\\n\"\n",
        "            for obs in self.all_parameters:\n",
        "                if isinstance(obs, tuple):\n",
        "                    name = obs[0]\n",
        "                    args = obs[1:]\n",
        "                    argnames = Observable[name].arguments\n",
        "                    md += \"- {}\".format(Observable[name].tex)\n",
        "                    for i, arg in enumerate(args):\n",
        "                        md += \", `{}` = {}\".format(argnames[i], arg)\n",
        "                    md += \"\\n\"\n",
        "                else:\n",
        "                    md += \"- {}\\n\".format(Observable[obs].tex)\n",
        "        return md\n"
      ]
    }
  ]
}